#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
from dotenv import load_dotenv

# LangChain imports
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain_community.vectorstores import Chroma

# Google Gemini imports
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings

load_dotenv()  # –∏—â–µ—Ç —Ñ–∞–π–ª .env –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not GOOGLE_API_KEY:
    raise ValueError("GOOGLE_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω! –ü—Ä–æ–≤–µ—Ä—å —Ñ–∞–π–ª .env")

DOC_PATH = "../Data/Knowledge/productivity.md"

if not os.path.isfile(DOC_PATH):
    raise FileNotFoundError(f"–§–∞–π–ª —Å –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω: {DOC_PATH}")

loader = TextLoader(DOC_PATH, encoding="utf-8")
documents = loader.load()

text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
docs = text_splitter.split_documents(documents)

embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
vectorstore = Chroma.from_documents(docs, embeddings, persist_directory="./chroma_db")

retriever = vectorstore.as_retriever()
qa = RetrievalQA.from_chain_type(
    llm=ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0),
    retriever=retriever
)

print("ü§ñ Female Task Planner AI (Gemini) –∑–∞–ø—É—â–µ–Ω! –í–≤–µ–¥–∏ –≤–æ–ø—Ä–æ—Å (–∏–ª–∏ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞).")

while True:
    query = input("\n–¢–≤–æ–π –≤–æ–ø—Ä–æ—Å: ")
    if query.lower() in ["exit", "quit", "–≤—ã—Ö–æ–¥"]:
        print("üëã –í—ã—Ö–æ–¥. –î–æ –≤—Å—Ç—Ä–µ—á–∏!")
        break
    try:
        answer = qa.run(query)
        print(f"\nAI —Å–æ–≤–µ—Ç: {answer}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
